{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM server is running. Starting inference process...\n",
      "Row 1 response: Once upon a time, there was a little kitten named Whiskers who lived with her family in a cozy cottage at the edge of the forest. One day, while exploring the woods, she wandered too far from home and became lost. As night fell, poor Whiskers cried for help but no one came. She huddled under a bush, shivering and alone.\n",
      "\n",
      "The next morning, as she searched for food, she met a wise old owl perched on a branch. \"Where are you going, little one?\" asked the owl. Whiskers told him her sad story and how much she missed her family. The owl listened carefully and then said, \"I know where your home is. Follow me.\"\n",
      "\n",
      "Together they flew over hills and valleys until they reached the outskirts of the village. There, the owl pointed towards a distant cottage and said, \"That's where you belong. Now go find your family.\" With renewed hope, Whiskers set off towards home.\n",
      "\n",
      "As she walked through the fields and pastures, she encountered many creatures along the way - a friendly dog, a playful rabbit, even a mischievous fox. They all offered their assistance, but Whiskers knew that only her own determination could bring her back safely.\n",
      "\n",
      "Finally, after days of wandering, she arrived at her doorstep, exhausted but relieved. Her family welcomed her with open arms and tears of joy. From that day forward, Whiskers never strayed too far from home again, always remembering the lesson she learned on her journey - that sometimes we must face challenges alone, but with courage and perseverance, we can overcome them and find our way back to those we love.\n",
      "Row 2 response: The theory of relativity is a scientific concept that explains how gravity works, and it was developed by Albert Einstein. It states that everything with mass or energy has gravitational pull on other objects with mass or energy. This means that even small objects like planets have a gravitational force that affects larger objects like stars and galaxies. \n",
      "\n",
      "The theory also suggests that time and space are not absolute but rather relative to an observer's motion. In simpler terms, this means that if you were traveling at high speeds through space, your perception of time would be different than someone who was standing still on Earth. Additionally, the theory proposes that the speed of light is always constant, regardless of the observer's movement.\n",
      "Row 3 response: No, because it is not a living organism and does not have the ability to reproduce or grow. It may mimic certain aspects of life but it cannot truly experience consciousness in the same way that humans do.\n",
      "Inference process completed. Responses saved to 'mass_infer_responses.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import html\n",
    "\n",
    "INPUT_FILE = \"mass_infer_data.xlsx\"\n",
    "OUTPUT_FILE = \"mass_infer_responses.csv\"\n",
    "CHATBOT_HOST = \"127.0.0.1:6000\"\n",
    "CHATBOT_URI = f\"http://{CHATBOT_HOST}/api/v1/chat\"\n",
    "OUTPUT_FOLDER = \"data\" # Default, should NOT be changed\n",
    "\n",
    "output_path = os.path.join(OUTPUT_FOLDER, OUTPUT_FILE)\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "dummy_request = {\n",
    "    \"user_input\": \"Say yes.\",\n",
    "    \"max_new_tokens\": 10,\n",
    "    \"auto_max_new_tokens\": False,\n",
    "    \"max_tokens_second\": 0,\n",
    "    \"history\": {\"internal\": [], \"visible\": []},\n",
    "    \"mode\": \"instruct\",  # Valid options: 'chat', 'chat-instruct', 'instruct'\n",
    "    \"character\": \"Example\",\n",
    "    \"instruction_template\": \"Vicuna-v1.1\",  # Will get autodetected if unset\n",
    "    \"your_name\": \"You\",\n",
    "    # 'name1': 'name of user', # Optional\n",
    "    # 'name2': 'name of character', # Optional\n",
    "    # 'context': 'character context', # Optional\n",
    "    # 'greeting': 'greeting', # Optional\n",
    "    # 'name1_instruct': 'You', # Optional\n",
    "    # 'name2_instruct': 'Assistant', # Optional\n",
    "    # 'context_instruct': 'context_instruct', # Optional\n",
    "    # 'turn_template': 'turn_template', # Optional\n",
    "    \"regenerate\": False,\n",
    "    \"_continue\": False,\n",
    "    \"chat_instruct_command\": 'Continue the chat dialogue below. Write a single reply for the character \"<|character|>\".\\n\\n<|prompt|>',\n",
    "    # Generation params. If 'preset' is set to different than 'None', the values\n",
    "    # in presets/preset-name.yaml are used instead of the individual numbers.\n",
    "    \"preset\": \"None\",\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.1,\n",
    "    \"typical_p\": 1,\n",
    "    \"epsilon_cutoff\": 0,  # In units of 1e-4\n",
    "    \"eta_cutoff\": 0,  # In units of 1e-4\n",
    "    \"tfs\": 1,\n",
    "    \"top_a\": 0,\n",
    "    \"repetition_penalty\": 1.18,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"repetition_penalty_range\": 0,\n",
    "    \"top_k\": 40,\n",
    "    \"min_length\": 0,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "    \"num_beams\": 1,\n",
    "    \"penalty_alpha\": 0,\n",
    "    \"length_penalty\": 1,\n",
    "    \"early_stopping\": False,\n",
    "    \"mirostat_mode\": 0,\n",
    "    \"mirostat_tau\": 5,\n",
    "    \"mirostat_eta\": 0.1,\n",
    "    \"grammar_string\": \"\",\n",
    "    \"guidance_scale\": 1,\n",
    "    \"negative_prompt\": \"\",\n",
    "    \"seed\": -1,\n",
    "    \"add_bos_token\": True,\n",
    "    \"truncation_length\": 2048,\n",
    "    \"ban_eos_token\": False,\n",
    "    \"custom_token_bans\": \"\",\n",
    "    \"skip_special_tokens\": True,\n",
    "    \"stopping_strings\": [],\n",
    "}\n",
    "\n",
    "\n",
    "# Function to read the input file based on its extension\n",
    "def read_input_file(file_path):\n",
    "    _, file_extension = os.path.splitext(file_path)\n",
    "    if file_extension.lower() == \".csv\":\n",
    "        return pd.read_csv(file_path)\n",
    "    elif file_extension.lower() in [\".xls\", \".xlsx\"]:\n",
    "        return pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please provide a .csv or .xlsx file.\")\n",
    "\n",
    "\n",
    "# Function to check server connectivity\n",
    "def check_server_connectivity(uri):\n",
    "    try:\n",
    "        response = requests.post(CHATBOT_URI, json=dummy_request)\n",
    "        return response.status_code == 200\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error checking server connectivity: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Check if the LLM server can be connected to\n",
    "if not check_server_connectivity(CHATBOT_URI):\n",
    "    print(\"Cannot connect to the LLM server. Please check the server status.\")\n",
    "else:\n",
    "    print(\"LLM server is running. Starting inference process...\")\n",
    "    try:\n",
    "        df = read_input_file(INPUT_FILE)\n",
    "        # Replace the string literals with actual newline characters\n",
    "        df.replace({r\"\\\\n\": \"\\n\"}, regex=True, inplace=True)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "    # Prepare a DataFrame to store responses\n",
    "    responses = []\n",
    "\n",
    "    history = {\"internal\": [], \"visible\": []}\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        request_data = {\n",
    "            \"user_input\": row[\"user_input\"],\n",
    "            \"max_new_tokens\": 500,\n",
    "            \"auto_max_new_tokens\": False,\n",
    "            \"max_tokens_second\": 0,\n",
    "            \"history\": history,\n",
    "            \"mode\": \"instruct\",  # Valid options: 'chat', 'chat-instruct', 'instruct'\n",
    "            \"character\": \"Example\",\n",
    "            \"instruction_template\": \"Vicuna-v1.1\",  # Will get autodetected if unset\n",
    "            \"your_name\": \"You\",\n",
    "            # 'name1': 'name of user', # Optional\n",
    "            # 'name2': 'name of character', # Optional\n",
    "            # 'context': 'character context', # Optional\n",
    "            # 'greeting': 'greeting', # Optional\n",
    "            \"name1_instruct\": row[\"name1_instruct\"],\n",
    "            \"name2_instruct\": row[\"name2_instruct\"],\n",
    "            \"context_instruct\": row[\"context_instruct\"],\n",
    "            \"turn_template\": row[\"turn_template\"],\n",
    "            \"regenerate\": False,\n",
    "            \"_continue\": False,\n",
    "            \"chat_instruct_command\": 'Continue the chat dialogue below. Write a single reply for the character \"<|character|>\".\\n\\n<|prompt|>',\n",
    "            # Generation params. If 'preset' is set to different than 'None', the values\n",
    "            # in presets/preset-name.yaml are used instead of the individual numbers.\n",
    "            \"preset\": \"None\",\n",
    "            \"do_sample\": True,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.1,\n",
    "            \"typical_p\": 1,\n",
    "            \"epsilon_cutoff\": 0,  # In units of 1e-4\n",
    "            \"eta_cutoff\": 0,  # In units of 1e-4\n",
    "            \"tfs\": 1,\n",
    "            \"top_a\": 0,\n",
    "            \"repetition_penalty\": 1.18,\n",
    "            \"repetition_penalty_range\": 0,\n",
    "            \"top_k\": 40,\n",
    "            \"min_length\": 0,\n",
    "            \"no_repeat_ngram_size\": 0,\n",
    "            \"num_beams\": 1,\n",
    "            \"penalty_alpha\": 0,\n",
    "            \"length_penalty\": 1,\n",
    "            \"early_stopping\": False,\n",
    "            \"mirostat_mode\": 0,\n",
    "            \"mirostat_tau\": 5,\n",
    "            \"mirostat_eta\": 0.1,\n",
    "            \"grammar_string\": \"\",\n",
    "            \"guidance_scale\": 1,\n",
    "            \"negative_prompt\": \"\",\n",
    "            \"seed\": -1,\n",
    "            \"add_bos_token\": True,\n",
    "            \"truncation_length\": 2048,\n",
    "            \"ban_eos_token\": False,\n",
    "            \"custom_token_bans\": \"\",\n",
    "            \"skip_special_tokens\": True,\n",
    "            \"stopping_strings\": [],\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Send request to the server\n",
    "            response = requests.post(CHATBOT_URI, json=request_data)\n",
    "\n",
    "            # Process the response\n",
    "            if response.status_code == 200:\n",
    "                results = response.json()[\"results\"]\n",
    "                chatbot_reply = results[0][\"history\"][\"visible\"][-1][1]\n",
    "                # Decode HTML entities in the response\n",
    "                chatbot_reply = html.unescape(chatbot_reply)\n",
    "            else:\n",
    "                print(f\"Error with status code: {response.status_code}\")\n",
    "                chatbot_reply = \"Error occurred during request.\"\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            chatbot_reply = \"Server error occurred.\"\n",
    "        print(f\"Row {index+1} response: {chatbot_reply}\")\n",
    "        responses.append(\n",
    "            {\"user_input\": row[\"user_input\"], \"chatbot_reply\": chatbot_reply}\n",
    "        )\n",
    "\n",
    "    # Convert the list of dicts to a DataFrame\n",
    "    responses_df = pd.DataFrame(responses)\n",
    "\n",
    "    # Combine the input df with responses_df to keep the same column format\n",
    "    final_df = pd.concat([df.iloc[:, :-1], responses_df[\"chatbot_reply\"]], axis=1)\n",
    "\n",
    "    # Save the final DataFrame to a new CSV file\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    print(\"Inference process completed. Responses saved to 'mass_infer_responses.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  name1_instruct name2_instruct  \\\n",
      "0          USER:     ASSISTANT:   \n",
      "1          USER:     ASSISTANT:   \n",
      "2          USER:     ASSISTANT:   \n",
      "\n",
      "                                    context_instruct  \\\n",
      "0  A chat between a curious user and an artificia...   \n",
      "1  A chat between a curious user and an artificia...   \n",
      "2  A chat between a curious user and an artificia...   \n",
      "\n",
      "                                       turn_template  \\\n",
      "0  <|user|> <|user-message|>\\n<|bot|> <|bot-messa...   \n",
      "1  <|user|> <|user-message|>\\n<|bot|> <|bot-messa...   \n",
      "2  <|user|> <|user-message|>\\n<|bot|> <|bot-messa...   \n",
      "\n",
      "                                          user_input  \n",
      "0  Write a short story about a lost kitten findin...  \n",
      "1  Explain the theory of relativity in simple terms.  \n",
      "2  Can artificial intelligence ever be considered...  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name1_instruct</th>\n",
       "      <th>name2_instruct</th>\n",
       "      <th>context_instruct</th>\n",
       "      <th>turn_template</th>\n",
       "      <th>user_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER:</td>\n",
       "      <td>ASSISTANT:</td>\n",
       "      <td>A chat between a curious user and an artificia...</td>\n",
       "      <td>&lt;|user|&gt; &lt;|user-message|&gt;\\n&lt;|bot|&gt; &lt;|bot-messa...</td>\n",
       "      <td>Write a short story about a lost kitten findin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USER:</td>\n",
       "      <td>ASSISTANT:</td>\n",
       "      <td>A chat between a curious user and an artificia...</td>\n",
       "      <td>&lt;|user|&gt; &lt;|user-message|&gt;\\n&lt;|bot|&gt; &lt;|bot-messa...</td>\n",
       "      <td>Explain the theory of relativity in simple terms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USER:</td>\n",
       "      <td>ASSISTANT:</td>\n",
       "      <td>A chat between a curious user and an artificia...</td>\n",
       "      <td>&lt;|user|&gt; &lt;|user-message|&gt;\\n&lt;|bot|&gt; &lt;|bot-messa...</td>\n",
       "      <td>Can artificial intelligence ever be considered...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name1_instruct name2_instruct  \\\n",
       "0          USER:     ASSISTANT:   \n",
       "1          USER:     ASSISTANT:   \n",
       "2          USER:     ASSISTANT:   \n",
       "\n",
       "                                    context_instruct  \\\n",
       "0  A chat between a curious user and an artificia...   \n",
       "1  A chat between a curious user and an artificia...   \n",
       "2  A chat between a curious user and an artificia...   \n",
       "\n",
       "                                       turn_template  \\\n",
       "0  <|user|> <|user-message|>\\n<|bot|> <|bot-messa...   \n",
       "1  <|user|> <|user-message|>\\n<|bot|> <|bot-messa...   \n",
       "2  <|user|> <|user-message|>\\n<|bot|> <|bot-messa...   \n",
       "\n",
       "                                          user_input  \n",
       "0  Write a short story about a lost kitten findin...  \n",
       "1  Explain the theory of relativity in simple terms.  \n",
       "2  Can artificial intelligence ever be considered...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
